import cv2
import mediapipe as mp
import numpy as np
import time
import threading
import requests
import traceback
from queue import Queue, Empty
from collections import deque

# ================== C·∫§U H√åNH ==================
URL_SNAPSHOT      = "http://172.16.10.59/cam-mid.jpg"  # <-- ƒë·ªïi IP/endpoint c·ªßa b·∫°n
CONNECT_TIMEOUT   = 1.5
READ_TIMEOUT      = 2.5
TARGET_FETCH_FPS  = 6

# K·∫øt n·ªëi ESP32 MCU (g·ª≠i tr·∫°ng th√°i)
ESP32_IP = "172.16.10.86"
URL = f"http://{ESP32_IP}/send"

# ==== H√ÄM G·ª¨I T√çN HI·ªÜU SANG ESP32 (ƒë·∫∑t s·ªõm, top-level) ====
def send_message(msg):
    try:
        response = requests.get(URL, params={"msg": msg}, timeout=3)
        print("üì® G·ª≠i:", msg)
        print("üì¨ ESP32 ph·∫£n h·ªìi:", response.text)
    except Exception as e:
        print("‚ùå L·ªói khi g·ª≠i d·ªØ li·ªáu:", e)

# X·ª≠ l√Ω & hi·ªÉn th·ªã
PROCESS_WIDTH     = 416
DISPLAY_WIDTH     = 800
DISPLAY_FPS       = 15
SHOW_WINDOW       = True
DRAW_OVERLAY      = True

# Mediapipe & theo d√µi
MAX_TRACKS        = 3
ASSIGN_DIST_RATIO = 0.2
LOST_SEC          = 1.0
MESH_MIN_INTERVAL = 0.12   # ~8Hz

# ====== Ng∆∞·ª°ng ph√°t hi·ªán (V·ª™A PH·∫¢I) ======
# EAR tuy·ªát ƒë·ªëi (fallback)
EAR_SLEEP_ABS     = 0.21
EAR_DROWSY_ABS    = 0.27
CLOSED_EYES_TIME  = 1.2

# Th√≠ch nghi theo ng∆∞·ªùi: t·ª∑ l·ªá so v·ªõi baseline m·∫Øt m·ªü
EAR_SLEEP_RATIO   = 0.60   # ng·ªß n·∫øu EAR < 60% baseline
EAR_DROWSY_RATIO  = 0.80   # l·ªù ƒë·ªù n·∫øu EAR < 80% baseline
BASELINE_MIN      = 0.22   # k·∫πp an to√†n
BASELINE_MAX      = 0.40
BASELINE_ALPHA    = 0.05   # EMA ch·∫≠m (h·ªçc t·ª´ t·ª´ khi ƒëang t·ªânh)

# Ng√°p / l·ªù ƒë·ªù (ƒë·ªÉ ra "Met moi", KH√îNG k√≠ch "Ngu gat")
MAR_YAWN          = 0.35
DROWSY_HOLD_SEC   = 1.0
YAWN_HOLD_SEC     = 0.6

# ƒê·∫ßu nghi√™ng (roll) ‚Äì ch·ªëng b√°o nh·∫ßm khi l·∫Øc nhanh
TILT_DEG_SLEEP    = 22.0   # |roll| ‚â• 22¬∞
TILT_HOLD_SEC     = 0.8    # gi·ªØ ‚â• 0.8s
ROLL_VEL_MAX      = 120.0  # deg/s; n·∫øu l·∫Øc nhanh h∆°n ‚Üí KH√îNG coi l√† ng·ªß g·∫≠t

# Wake-up (tho√°t 'Ngu gat' khi ƒë√£ t·ªânh)
WAKE_EAR          = 0.27
WAKE_TILT_DEG     = 8.0
WAKE_HOLD_SEC     = 0.4

# ========== Gi·ªØ ID ·ªïn ƒë·ªãnh (CH·ªêNG NH·∫¢Y P#) ==========
REACQUIRE_SEC     = 1.2
REACQ_DIST_RATIO  = 0.35
STICKY_IOU_BONUS  = 0.50

# ================== FETCHER ==================
class SnapshotFetcher:
    def __init__(self, url, target_fps=6, connect_to=1.5, read_to=2.5):
        self.url = url
        self.min_dt = 1.0 / max(1, int(target_fps))
        self.connect_to = connect_to
        self.read_to    = read_to
        self.sess = requests.Session()
        self.sess.headers.update({
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Connection": "keep-alive",
            "User-Agent": "opencv-python"
        })
        self._lock = threading.Lock()
        self._frame = None
        self._stop = False
        self._t = threading.Thread(target=self._run, daemon=True)
        self._t.start()

    def _run(self):
        last = 0.0
        while not self._stop:
            dt = time.time() - last
            if dt < self.min_dt:
                time.sleep(self.min_dt - dt)
            try:
                r = self.sess.get(self.url, timeout=(self.connect_to, self.read_to))
                if r.status_code == 200:
                    arr = np.frombuffer(r.content, dtype=np.uint8)
                    frm = cv2.imdecode(arr, cv2.IMREAD_COLOR)
                    if frm is not None:
                        with self._lock:
                            self._frame = frm
                        last = time.time()
            except Exception:
                time.sleep(0.05)

    def read(self):
        with self._lock:
            return None if self._frame is None else self._frame.copy()

    def close(self):
        self._stop = True
        try: self._t.join(timeout=1.0)
        except: pass
        try: self.sess.close()
        except: pass

# ================== MEDIAPIPE ==================
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=False,
    max_num_faces=MAX_TRACKS,
    refine_landmarks=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

LEFT_EYE  = [33, 160, 158, 133, 153, 144]
RIGHT_EYE = [263, 387, 385, 362, 380, 373]
MOUTH_TOP, MOUTH_BOTTOM, MOUTH_LEFT, MOUTH_RIGHT = 13, 14, 61, 291
EYE_OUTER_LEFT_IDX  = 33
EYE_OUTER_RIGHT_IDX = 263

def eye_aspect_ratio(landmarks, eye_idx, W, H):
    pts = [(landmarks[i].x * W, landmarks[i].y * H) for i in eye_idx]
    p1, p2, p3, p4, p5, p6 = [np.array(p) for p in pts]
    A = np.linalg.norm(p2 - p6)
    B = np.linalg.norm(p3 - p5)
    C = np.linalg.norm(p1 - p4) + 1e-6
    return (A + B) / (2.0 * C)

def mouth_aspect_ratio(landmarks, W, H):
    top = np.array([landmarks[MOUTH_TOP].x * W, landmarks[MOUTH_TOP].y * H])
    bot = np.array([landmarks[MOUTH_BOTTOM].x * W, landmarks[MOUTH_BOTTOM].y * H])
    left = np.array([landmarks[MOUTH_LEFT].x * W, landmarks[MOUTH_LEFT].y * H])
    right = np.array([landmarks[MOUTH_RIGHT].x * W, landmarks[MOUTH_RIGHT].y * H])
    return np.linalg.norm(top - bot) / (np.linalg.norm(left - right) + 1e-6)

def head_roll_deg(landmarks, W, H):
    pL = np.array([landmarks[EYE_OUTER_LEFT_IDX].x * W,  landmarks[EYE_OUTER_LEFT_IDX].y * H])
    pR = np.array([landmarks[EYE_OUTER_RIGHT_IDX].x * W, landmarks[EYE_OUTER_RIGHT_IDX].y * H])
    dy = pR[1] - pL[1]
    dx = (pR[0] - pL[0]) + 1e-6
    return float(np.degrees(np.arctan2(dy, dx)))

def seconds_since(t0): 
    return 0.0 if t0 is None else (time.time() - t0)

def bbox_iou(b1, b2):
    if b1 is None or b2 is None:
        return 0.0
    x11,y11,x12,y12 = b1
    x21,y21,x22,y22 = b2
    xi1, yi1 = max(x11,x21), max(y11,y21)
    xi2, yi2 = min(x12,x22), min(y12,y22)
    iw, ih = max(0, xi2-xi1), max(0, yi2-yi1)
    inter = iw*ih
    a1 = max(0, x12-x11) * max(0, y12-y11)
    a2 = max(0, x22-x21) * max(0, y22-y21)
    union = a1 + a2 - inter + 1e-6
    return float(inter/union)

# ====== tracks & logic ======
tracks = {
    tid: {
        "active": False,
        "cx": None, "cy": None,
        # timers
        "t_eye_closed_start": None,
        "t_drowsy_start": None,
        "t_yawn_start": None,
        "t_wake_start": None,
        "t_tilt_start": None,
        # state
        "status": "Tr·ªëng",
        "last_seen": 0.0,
        # last metrics (th√¥)
        "EAR_last": None, "MAR_last": None, "ROLL_last": None,
        # gi·ªØ ID ·ªïn ƒë·ªãnh
        "vx": 0.0, "vy": 0.0,
        "last_bbox": None,
        # === b·ªô l·ªçc & baseline cho logic ===
        "ear_filt": None, "roll_filt": None, "roll_vel_filt": 0.0,
        "ear_open_baseline": None,
        "last_logic_ts": None,
    } for tid in range(1, MAX_TRACKS + 1)
}

# === Theo d√µi tr·∫°ng th√°i ƒë√£ g·ª≠i cho t·ª´ng P (tr√°nh spam theo khung h√¨nh) ===
prev_present = {tid: False for tid in tracks}   # Khung tr∆∞·ªõc P# c√≥ xu·∫•t hi·ªán (bbox) hay kh√¥ng
last_sent    = {tid: None  for tid in tracks}   # "DETECTED"/"DROWSINESS"/"UNDETECTED"

def reset_track(tid, deactivate=False, cx=None, cy=None):
    tr = tracks[tid]
    tr["t_eye_closed_start"] = None
    tr["t_drowsy_start"] = None
    tr["t_yawn_start"] = None
    tr["t_wake_start"] = None
    tr["t_tilt_start"] = None
    tr["status"] = "Tr·ªëng" if deactivate else "Binh thuong"
    tr["EAR_last"] = None
    tr["MAR_last"] = None
    tr["ROLL_last"] = None
    tr["cx"], tr["cy"] = cx, cy
    tr["vx"], tr["vy"] = 0.0, 0.0
    tr["last_bbox"] = None
    tr["ear_filt"] = None
    tr["roll_filt"] = None
    tr["roll_vel_filt"] = 0.0
    tr["ear_open_baseline"] = None
    tr["last_logic_ts"] = None
    tr["last_seen"] = time.time()
    tr["active"] = not deactivate

# ========== GH√âP TRACK ·ªîN ƒê·ªäNH ==========
def assign_faces_to_tracks(dets, W, H):
    assigned = []
    used_tids = set()
    now = time.time()
    dist_th_active = ASSIGN_DIST_RATIO * min(W, H)
    dist_th_reacq  = REACQ_DIST_RATIO  * min(W, H)
    dets = sorted(dets, key=lambda d: d["area"], reverse=True)

    for det in dets:
        cx, cy = det["cx"], det["cy"]

        # 1) Active + d·ª± ƒëo√°n + IoU bonus
        best_tid, best_score = None, 1e9
        for tid, tr in tracks.items():
            if tid in used_tids or not tr["active"] or tr["cx"] is None:
                continue
            px = tr["cx"] + tr["vx"]
            py = tr["cy"] + tr["vy"]
            d  = np.hypot(cx - px, cy - py)
            iou = bbox_iou(det["bbox"], tr["last_bbox"])
            score = d * (1.0 - STICKY_IOU_BONUS * iou)
            if score < best_score:
                best_score, best_tid = score, tid

        if best_tid is not None and best_score <= dist_th_active:
            used_tids.add(best_tid)
            assigned.append((best_tid, det))
            continue

        # 2) Re-acquire trong REACQUIRE_SEC
        best_tid, best_d = None, 1e9
        for tid, tr in tracks.items():
            if tid in used_tids or tr["active"] or tr["cx"] is None:
                continue
            if (now - tr["last_seen"]) > REACQUIRE_SEC:
                continue
            d = np.hypot(cx - tr["cx"], cy - tr["cy"])
            if d < best_d:
                best_d, best_tid = d, tid

        if best_tid is not None and best_d <= dist_th_reacq:
            tr = tracks[best_tid]
            tr["active"] = True
            used_tids.add(best_tid)
            assigned.append((best_tid, det))
            continue

        # 3) B·∫≠t √¥ tr·ªëng (∆∞u ti√™n √¥ tr·ªëng l√¢u nh·∫•t)
        oldest_age, free_tid = -1, None
        for tid, tr in tracks.items():
            if tid in used_tids: continue
            if not tr["active"]:
                age = now - tr["last_seen"]
                if age > oldest_age:
                    oldest_age, free_tid = age, tid
        if free_tid is not None:
            reset_track(free_tid, deactivate=False, cx=cx, cy=cy)
            used_tids.add(free_tid)
            assigned.append((free_tid, det))

    # 4) C·∫≠p nh·∫≠t v·ªã tr√≠/v·∫≠n t·ªëc/bbox
    for tid, det in assigned:
        tr = tracks[tid]
        if tr["cx"] is not None:
            dx = det["cx"] - tr["cx"]
            dy = det["cy"] - tr["cy"]
            alpha = 0.7
            tr["vx"] = alpha * dx + (1 - alpha) * tr["vx"]
            tr["vy"] = alpha * dy + (1 - alpha) * tr["vy"]
        tr["cx"], tr["cy"] = det["cx"], det["cy"]
        tr["last_bbox"] = det["bbox"]
        tr["last_seen"] = now

    # 5) Chuy·ªÉn inactive n·∫øu m·∫•t l√¢u
    for tid, tr in tracks.items():
        if tr["active"] and tid not in [t for t, _ in assigned]:
            if now - tr["last_seen"] > LOST_SEC:
                tr["active"] = False
    return assigned

# ================== Worker ==================
class FaceMeshWorker:
    def __init__(self, process_width=416, mesh_min_interval=0.12):
        self.q = Queue(maxsize=1)
        self.result = None
        self.r_lock = threading.Lock()
        self.stop = False
        self.process_width = process_width
        self.mesh_min_interval = mesh_min_interval
        self.last_mesh_ts = 0.0
        self.smooth_ear = {tid: deque(maxlen=5) for tid in tracks}
        self.smooth_mar = {tid: deque(maxlen=5) for tid in tracks}
        self.t = threading.Thread(target=self._run, daemon=True)
        self.t.start()

    def submit(self, frame):
        try:
            if self.q.full():
                self.q.get_nowait()
            self.q.put_nowait(frame)
        except Exception:
            pass

    def get_result(self):
        with self.r_lock:
            return None if self.result is None else self.result.copy()

    def close(self):
        self.stop = True
        try: self.t.join(timeout=1.0)
        except: pass

    def _run(self):
        while not self.stop:
            try:
                frame = self.q.get(timeout=0.2)
            except Empty:
                continue

            # Resize x·ª≠ l√Ω nhanh
            H0, W0 = frame.shape[:2]
            if W0 > self.process_width:
                new_h = int(H0 * self.process_width / W0)
                proc = cv2.resize(frame, (self.process_width, new_h), interpolation=cv2.INTER_AREA)
            else:
                proc = frame
            H, W = proc.shape[:2]

            now_ts = time.time()
            if (now_ts - self.last_mesh_ts) < self.mesh_min_interval:
                continue

            rgb = cv2.cvtColor(proc, cv2.COLOR_BGR2RGB)
            res = face_mesh.process(rgb)

            detections = []
            if res and res.multi_face_landmarks:
                for face in res.multi_face_landmarks:
                    lm = face.landmark
                    left_ear  = eye_aspect_ratio(lm, LEFT_EYE,  W, H)
                    right_ear = eye_aspect_ratio(lm, RIGHT_EYE, W, H)
                    EAR  = float((left_ear + right_ear) / 2.0)
                    MAR  = float(mouth_aspect_ratio(lm, W, H))
                    ROLL = float(head_roll_deg(lm, W, H))

                    xs = [int(p.x * W) for p in lm]
                    ys = [int(p.y * H) for p in lm]
                    x1, y1 = max(min(xs), 0), max(min(ys), 0)
                    x2, y2 = min(max(xs), W - 1), min(max(ys), H - 1)
                    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                    area = max(1, (x2 - x1) * (y2 - y1))

                    detections.append({"EAR": EAR, "MAR": MAR, "ROLL": ROLL,
                                       "bbox": (x1, y1, x2, y2),
                                       "cx": cx, "cy": cy, "area": area})

            pairs = assign_faces_to_tracks(detections, W, H) if detections else []

            overlay = []
            for tid, det in pairs:
                EAR, MAR, ROLL = det["EAR"], det["MAR"], det["ROLL"]
                x1, y1, x2, y2  = det["bbox"]
                tr = tracks[tid]

                # ====== L·ªåC M·ªÄM cho logic (EMA) ======
                dt = now_ts - tr["last_logic_ts"] if tr["last_logic_ts"] else 1/8.0
                dt = max(0.05, min(0.5, dt))  # k·∫πp an to√†n
                a_ear, a_roll, a_vel = 0.5, 0.5, 0.6
                tr["ear_filt"]  = EAR  if tr["ear_filt"]  is None else (a_ear*EAR  + (1-a_ear)*tr["ear_filt"])
                tr["roll_filt"] = ROLL if tr["roll_filt"] is None else (a_roll*ROLL + (1-a_roll)*tr["roll_filt"])
                # v·∫≠n t·ªëc quay ƒë·∫ßu (deg/s), l·ªçc ti·∫øp
                roll_vel_inst = (tr["roll_filt"] - (tr["ROLL_last"] if tr["ROLL_last"] is not None else tr["roll_filt"])) / dt
                tr["roll_vel_filt"] = a_vel*roll_vel_inst + (1-a_vel)*tr["roll_vel_filt"]

                EARf  = tr["ear_filt"]
                ROLLf = tr["roll_filt"]
                VROLL = abs(tr["roll_vel_filt"])

                # ====== C·∫¨P NH·∫¨T BASELINE M·∫ÆT M·ªû ======
                if tr["status"] != "Ngu gat" and EARf is not None and (abs(ROLLf) < 12.0):
                    if (tr["ear_open_baseline"] is None) and (EARf > 0.24):
                        tr["ear_open_baseline"] = EARf
                    elif tr["ear_open_baseline"] is not None and EARf > 0.22:
                        tr["ear_open_baseline"] = (1-BASELINE_ALPHA)*tr["ear_open_baseline"] + BASELINE_ALPHA*EARf
                        tr["ear_open_baseline"] = max(BASELINE_MIN, min(BASELINE_MAX, tr["ear_open_baseline"]))

                # Ng∆∞·ª°ng EAR theo baseline (fallback tuy·ªát ƒë·ªëi)
                if tr["ear_open_baseline"] is not None:
                    ear_sleep_thr  = max(EAR_SLEEP_ABS,  tr["ear_open_baseline"]*EAR_SLEEP_RATIO)
                    ear_drowsy_thr = max(EAR_DROWSY_ABS, tr["ear_open_baseline"]*EAR_DROWSY_RATIO)
                else:
                    ear_sleep_thr  = EAR_SLEEP_ABS
                    ear_drowsy_thr = EAR_DROWSY_ABS

                # ===== NH·∫ÆM M·∫ÆT ƒë·ªß l√¢u -> Ngu gat =====
                if EARf < ear_sleep_thr:
                    if tr["t_eye_closed_start"] is None:
                        tr["t_eye_closed_start"] = now_ts
                    if seconds_since(tr["t_eye_closed_start"]) >= CLOSED_EYES_TIME:
                        tr["status"] = "Ngu gat"
                        tr["t_wake_start"] = None
                else:
                    tr["t_eye_closed_start"] = None

                # ===== NGHI√äNG ƒê·∫¶U ƒë·ªß l√¢u (v√† m·∫Øt kh√¥ng m·ªü to) -> Ngu gat =====
                if (abs(ROLLf) >= TILT_DEG_SLEEP) and (VROLL <= ROLL_VEL_MAX) and (EARf < ear_drowsy_thr):
                    if tr["t_tilt_start"] is None:
                        tr["t_tilt_start"] = now_ts
                    if seconds_since(tr["t_tilt_start"]) >= TILT_HOLD_SEC:
                        tr["status"] = "Ngu gat"
                        tr["t_wake_start"] = None
                else:
                    tr["t_tilt_start"] = None

                # ===== MET MOI =====
                if ear_sleep_thr <= EARf < ear_drowsy_thr:
                    if tr["t_drowsy_start"] is None:
                        tr["t_drowsy_start"] = now_ts
                else:
                    tr["t_drowsy_start"] = None

                if MAR > MAR_YAWN:
                    if tr["t_yawn_start"] is None:
                        tr["t_yawn_start"] = now_ts
                else:
                    tr["t_yawn_start"] = None

                d_ok = (seconds_since(tr["t_drowsy_start"]) >= DROWSY_HOLD_SEC)
                y_ok = (seconds_since(tr["t_yawn_start"])   >= YAWN_HOLD_SEC)
                if tr["status"] != "Ngu gat":
                    # N·∫øu mu·ªën "m·ªôt trong hai" l√† ƒë·ªß th√¨ d√πng (d_ok or y_ok)
                    tr["status"] = "Met moi" if (d_ok and y_ok) else "Binh thuong"
                else:
                    # ===== WAKE-UP =====
                    wake_thr = max(WAKE_EAR, (tr["ear_open_baseline"]*0.90 if tr["ear_open_baseline"] else WAKE_EAR))
                    if (EARf >= wake_thr) and (abs(ROLLf) <= WAKE_TILT_DEG):
                        if tr["t_wake_start"] is None:
                            tr["t_wake_start"] = now_ts
                        if seconds_since(tr["t_wake_start"]) >= WAKE_HOLD_SEC:
                            tr["status"] = "Binh thuong"
                            tr["t_wake_start"]   = None
                            tr["t_drowsy_start"] = None
                            tr["t_yawn_start"]   = None
                    else:
                        tr["t_wake_start"] = None

                # l∆∞u ch·ªâ s·ªë cho overlay + th·ªùi gian
                tr["EAR_last"]  = EAR
                tr["MAR_last"]  = MAR
                tr["ROLL_last"] = ROLLf
                tr["last_logic_ts"] = now_ts
                self.smooth_ear[tid].append(EAR)
                self.smooth_mar[tid].append(MAR)
                ear_show = float(np.mean(self.smooth_ear[tid]))
                mar_show = float(np.mean(self.smooth_mar[tid]))

                overlay.append({
                    "tid": tid,
                    "bbox": (x1, y1, x2, y2),
                    "status": tr["status"],
                    "EAR": ear_show,
                    "MAR": mar_show
                })

            self.last_mesh_ts = now_ts
            with self.r_lock:
                self.result = {"ts": now_ts, "proc_size": (W, H), "overlay": overlay}

# ================== MAIN LOOP ==================
cv2.setUseOptimized(True)

fetcher = SnapshotFetcher(URL_SNAPSHOT, target_fps=TARGET_FETCH_FPS,
                          connect_to=CONNECT_TIMEOUT, read_to=READ_TIMEOUT)
worker  = FaceMeshWorker(process_width=PROCESS_WIDTH, mesh_min_interval=MESH_MIN_INTERVAL)

if SHOW_WINDOW:
    cv2.namedWindow("Driver State (snapshot, 3-person, robust)", cv2.WINDOW_AUTOSIZE)

last_disp = 0.0

try:
    while True:
        frame = fetcher.read()
        if frame is None:
            if SHOW_WINDOW:
                blank = np.zeros((240, 320, 3), np.uint8)
                cv2.putText(blank, "No frame - check snapshot URL", (12, 120),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)
                cv2.imshow("Driver State (snapshot, 3-person, robust)", blank)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            continue

        worker.submit(frame)

        now = time.time()
        if SHOW_WINDOW and (now - last_disp) >= (1.0 / DISPLAY_FPS):
            last_disp = now
            H0, W0 = frame.shape[:2]
            if W0 != DISPLAY_WIDTH:
                disp_h = int(H0 * DISPLAY_WIDTH / W0)
                display = cv2.resize(frame, (DISPLAY_WIDTH, disp_h), interpolation=cv2.INTER_LINEAR)
            else:
                display = frame.copy()
            dispH, dispW = display.shape[:2]

            res = worker.get_result()
            if res and DRAW_OVERLAY:
                try:
                    Wp, Hp = res["proc_size"]
                    sx, sy = (dispW / float(Wp), dispH / float(Hp))

                    # T·∫≠p P ƒëang hi·ªán di·ªán ·ªü khung h√¨nh n√†y
                    present_now = set()

                    # --- V·∫Ω & g·ª≠i tr·∫°ng th√°i cho c√°c P c√≥ bbox ---
                    for item in res["overlay"]:
                        x1, y1, x2, y2 = item["bbox"]
                        X1, Y1, X2, Y2 = int(x1 * sx), int(y1 * sy), int(x2 * sx), int(y2 * sy)
                        tid = item["tid"]
                        st  = item["status"]
                        present_now.add(tid)

                        color = (0, 0, 255) if st == "Ngu gat" else (0, 165, 255) if st == "Met moi" else (0, 200, 0)
                        cv2.rectangle(display, (X1, Y1), (X2, Y2), color, 2)
                        cv2.putText(display, f"P{tid} {st}", (X1, max(20, Y1 - 8)),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

                        # === G·ª¨I TR·∫†NG TH√ÅI KHI C√ì BBOX ===
                        # - Ngu gat  -> "P#: DROWSINESS"
                        # - C√≤n l·∫°i  -> "P#: DETECTED"
                        label = "DROWSINESS" if st == "Ngu gat" else "DETECTED"
                        if last_sent[tid] != label:
                            send_message(f"P{tid}: {label}")
                            last_sent[tid] = label

                    # --- G·ª≠i UNDETECTED cho P v·ª´a bi·∫øn m·∫•t ---
                    for tid in tracks.keys():
                        if tid not in present_now and prev_present.get(tid, False):
                            if last_sent[tid] != "UNDETECTED":
                                send_message(f"P{tid}: UNDETECTED")
                                last_sent[tid] = "UNDETECTED"

                    # --- C·∫≠p nh·∫≠t c·ªù hi·ªán di·ªán cho v√≤ng k·∫ø ---
                    for tid in tracks.keys():
                        prev_present[tid] = (tid in present_now)

                except Exception as e:
                    print("‚ùå L·ªói ·ªü kh·ªëi overlay:", e)
                    traceback.print_exc()

            cv2.imshow("Driver State (snapshot, 3-person, robust)", display)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

except KeyboardInterrupt:
    pass
finally:
    worker.close()
    fetcher.close()
    face_mesh.close()
    if SHOW_WINDOW:
        cv2.destroyAllWindows()
